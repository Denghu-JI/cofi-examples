{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Polynomial Linear Regression\n\nTo get started, we look at a simple linear regression example with\n`cofi`.\n\nWe have a set of noisy data values, Y, measured at known locations, X,\nand wish to find the best fit degree 3 polynomial.\n\nThe function we are going to fit is: $y=-6-5x+2x^2+x^3$\n\n## Table of contents\n\n-   [Introduction](#introduction)\n-   Step 0 - [Import modules](#import)\n-   Step 1 - [Define the problem](#problem)\n-   Step 2 - [Define the inversion options](#options)\n-   Step 3 - [Run the inversion](#inversion)\n-   Step 4 - [Check out the result](#result)\n-   Summary - [a clean version of code above](#review)\n-   Next - [switching to a different inversion approach](#switch)\n\n## Introduction\n\nIn the workflow of `cofi`, there are three main components:\n`BaseProblem`, `InversionOptions`, and `Inversion`.\n\n-   `BaseProblem` defines three things: 1) the forward problem; 2) the\n    inversion parameter (model) space; and 3) the objective function to\n    be optimised\n-   `InversionOptions` describes details about how one wants to run the\n    inversion, including the inversion approach, backend tool and\n    solver-specific parameters.\n-   `Inversion` can be seen as an inversion engine that takes in the\n    above two as information, and will produce an `InversionResult` upon\n    running.\n\nFor each of the above components, there's a `summary()` method to check\nthe current status.\n\nSo a common workflow includes 4 steps:\n\n1.  define `BaseProblem`. This can be done:\n\n    -   either: through a series of set functions\n\n            inv_problem = BaseProblem()\n            inv_problem.set_objective(some_function_here)\n            inv_problem.set_initial_model(a_starting_point)\n\n    -   or: by subclassing `BaseProblem`\n\n            class MyOwnProblem(BaseProblem):\n                def __init__(self, initial_model, whatever_I_want_to_pass_in):\n                    self.initial_model = initial_model\n                    self.whatever_I_want_to_pass_in = whatever_I_want_to_pass_in\n                def objective(self, model):\n                    return some_objective_function_value\n\n2.  define `InversionOptions`. Some useful methods include:\n\n    -   `set_solving_method()` and `suggest_tools()`. Once you've set a\n        solving method (from \"least squares\" and \"optimisation\", more\n        will be supported), you can use `suggest_tools()` to see a list\n        of backend tools to choose from.\n\n3.  start an `Inversion`. This step is common:\n\n        inv = Inversion(inv_problem, inv_options)\n        result = inv.run()\n\n4.  analyse the result, workflow and redo your experiments with\n    different `InversionOptions`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# 0. Import modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\n\nfrom cofi import BaseProblem, InversionOptions, Inversion\n\nnp.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# 1. Define the problem\n\nA list of functions/properties that can be set to `BaseProblem` so far:\n\n-   `set_objective()`\n-   `set_gradient()`\n-   `set_hessian()`\n-   `set_hessian_times_vector()`\n-   `set_residual()`\n-   `set_jacobian()`\n-   `set_jacobian_times_vector()`\n-   `set_data_misfit()`\n-   `set_regularisation()`\n-   `set_dataset()`\n-   `set_dataset_from_file()`\n-   `set_initial_model()`\n-   `set_model_shape()`\n-   `set_bounds`\n-   `set_constraints`\n-   `name` (only useful when displaying this problem, no functional use)\n\nOther useful functions:\n\n-   `defined_components()` (review what have been set)\n-   `summary()` (better displayed information)\n-   `suggest_solvers()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# generate data with random Gaussian noise\nbasis_func = lambda x: np.array([x**i for i in range(4)]).T               # x -> G\n_m_true = np.array([-6,-5,2,1])                                           # m\n\nsample_size = 20                                                          # N\nx = np.random.choice(np.linspace(-3.5,2.5), size=sample_size)             # x\nforward_func = lambda m: basis_func(x) @ m                                # m -> y_synthetic\ny_observed = forward_func(_m_true) + np.random.normal(0,1,sample_size)    # d\n\n############## PLOTTING ###############################################################\n_x_plot = np.linspace(-3.5,2.5)\n_G_plot = basis_func(_x_plot)\n_y_plot = _G_plot @ _m_true\nplt.figure(figsize=(12,8))\nplt.plot(_x_plot, _y_plot, color=\"darkorange\", label=\"true model\")\nplt.scatter(x, y_observed, color=\"lightcoral\", label=\"observed data\")\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\n_=plt.legend()\n\n# define the problem\ninv_problem = BaseProblem()\ninv_problem.name = \"Polynomial Regression\"\ninv_problem.set_dataset(x, y_observed)\ninv_problem.set_forward(forward_func)\ninv_problem.set_jacobian(basis_func(x))\n\ninv_problem.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# 2. Define the inversion options\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options = InversionOptions()\ninv_options.summary()\n\ninv_options.suggest_tools()\n\ninv_options.set_solving_method(\"linear least square\")\ninv_options.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\nAs the \"summary\" suggested, you've set the solving method, so you can\nskip the step of setting a backend tool because there's a default one.\n\nIf there are more backend tool options, then use the following function\nto see available options and set your desired backend solver.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv_options.suggest_tools()\n\ninv_options.set_tool(\"scipy.linalg.lstsq\")\ninv_options.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# 3. Start an inversion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv = Inversion(inv_problem, inv_options)\ninv.summary()\n\ninv_result = inv.run()\ninv_result.success\n\ninv_result.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# 4. Check back your problem setting, inversion setting & result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inv.summary()\n\ny_synthetic = inv_problem.forward(inv_result.model)\n\n############## PLOTTING ###############################################################\n_x_plot = np.linspace(-3.5,2.5)\n_G_plot = basis_func(_x_plot)\n_y_plot = _G_plot @ _m_true\n_y_synth = _G_plot @ inv_result.model\nplt.figure(figsize=(12,8))\nplt.plot(_x_plot, _y_plot, color=\"darkorange\", label=\"true model\")\nplt.plot(_x_plot, _y_synth, color=\"seagreen\", label=\"least squares solution\")\nplt.scatter(x, y_observed, color=\"lightcoral\", label=\"original data\")\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\n_=plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we see the least squares solver (green curve) fits all of the data\nwell and is a close approximation of the true curve (orange).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# 5. Summary: a cleaner version of the above example\n\nFor review purpose, here are the minimal set of commands we've used to\nproduce the above result:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "######## Import and set random seed\nimport numpy as np\nfrom cofi import BaseProblem, InversionOptions, Inversion\n\nnp.random.seed(42)\n\n######## Write code for your forward problem\n_m_true = np.array([-6,-5,2,1])                                            # m\n_sample_size = 20                                                          # N\nx = np.random.choice(np.linspace(-3.5,2.5), size=_sample_size)             # x\nforward_func = lambda m: (np.array([x**i for i in range(4)]).T) @ m        # m -> y_synthetic\ny_observed = forward_func(_m_true) + np.random.normal(0,1,_sample_size)    # d\n\n######## Attach above information to a `BaseProblem`\ninv_problem = BaseProblem()\ninv_problem.name = \"Polynomial Regression\"\ninv_problem.set_dataset(x, y_observed)\ninv_problem.set_forward(forward_func)\ninv_problem.set_jacobian(basis_func(x))\n\n######## Specify how you'd like the inversion to run (via an `InversionOptions`)\ninv_options = InversionOptions()\ninv_options.set_tool(\"scipy.linalg.lstsq\")\n\n######## Pass `BaseProblem` and `InversionOptions` into `Inversion` and run\ninv = Inversion(inv_problem, inv_options)\ninv_result = inv.run()\n\n######## Now check out the result\nprint(f\"The inversion result from `scipy.linalg.lstsq`: {inv_result.model}\\n\")\ninv_result.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n\n# 6. Switching to a different inversion approach\n\nAlternatively, you can switch to a different inversion solver easily.\nHere we use a plain optimizer `scipy.optimize.minimize` to demonstrate\nthis ability.\n\nFor this backend solver to run successfully, some additional information\nshould be provided, otherwise we will raise an error to notify what\nadditional information is required by the solver.\n\nThere are different ways of defining information - Here in the code\nbelow, after we make clear how to calculate the data misfit and\nregularisation, the objective function is generated for you based on the\nforward function and dataset. Alternatively, you can pass in an\nobjective function directly using\n`inv_problem.set_objective(your_objective_func)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "######## Provide additional information\ninv_problem.set_initial_model(np.ones(4))\ninv_problem.set_data_misfit(\"L2\")\ninv_problem.set_regularisation(\"L2\", 0)\n\n######## Set a different tool\ninv_options_2 = InversionOptions()\ninv_options_2.set_tool(\"scipy.optimize.minimize\")\n\n######## Run it\ninv_2 = Inversion(inv_problem, inv_options_2)\ninv_result_2 = inv_2.run()\n\n######## Check result\nprint(f\"The inversion result from `scipy.optimize.minimize`: {inv_result_2.model}\\n\")\ninv_result_2.summary()\n\n######## Plot all together\n_x_plot = np.linspace(-3.5,2.5)\n_G_plot = basis_func(_x_plot)\n_y_plot = _G_plot @ _m_true\n_y_synth_2 = _G_plot @ inv_result_2.model\nplt.figure(figsize=(12,8))\nplt.plot(_x_plot, _y_plot, color=\"darkorange\", label=\"true model\")\nplt.plot(_x_plot, _y_synth, color=\"seagreen\", label=\"least squares solution\")\nplt.plot(_x_plot, _y_synth_2, color=\"cornflowerblue\", label=\"optimisation solution\")\nplt.scatter(x, y_observed, color=\"lightcoral\", label=\"original data\")\nplt.xlabel(\"X\")\nplt.ylabel(\"Y\")\n_=plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we see the (blue curve) is also a relatively good approximation of\nthe true curve (orange).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}